---
title: "Session notes day 2"
author: "Tim Riffe"
date: '2022-07-05'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Yesterday's exercises

```{r}
library(gapminder)
library(tidyverse)
# ?geom_smooth
ggplot(data = gapminder,
       mapping = aes(x = gdpPercap,
                     y = lifeExp)) +
  geom_point(alpha = .05) +
  scale_x_log10() +
  geom_smooth(method = "loess", color = "red") +
  geom_smooth(method = "lm", color = "orange") + 
  geom_smooth(method = "gam") +
  facet_wrap(~continent)

```
```{r}
filter(gapminder,
       continent != "Oceania")
# == 
filter(gapminder,
       year == 1952 | year == 2007)

filter(gapminder,
       year == min(year) | year == max(year))

filter(gapminder, 
       year %in% c(1952, 2007))

ggplot(data = filter(gapminder,
                     year %in% range(year),
                     continent != "Oceania"),
       mapping = aes(x = gdpPercap, 
                     fill = continent)) +
  geom_density(alpha = .5) +
  scale_x_log10() +
  facet_wrap(~year)
```

## pipes

Here we take the above plot code and unpack it into a clear sequence of steps. The ` %>%` (pipe) operator is used to pass a result from the left to the right. It takes the result of the operation on the left, and feeds it to the first argument of the function on the right, which in our case is always going to be `data`, so it works without needing to be explicit.

`Ctril + Shift + m`
```{r}
  # take the original gapminder data:
gapminder %>% 
  # then filter it to specific rows
  # based on logical conditions
  
  filter(year %in% range(year),
         continent != "Oceania") %>% 
  
  # then take that result and give it to ggplot()
  ggplot(mapping = aes(x = gdpPercap, 
                       fill = continent)) +
    geom_density(alpha = .5) +
    scale_x_log10() +
    facet_wrap(~year)
```

## other tidy functions besides `filter()`

### filter() and select()
Filtering is for rows
Selecting is for columns
```{r}
# select grabs columns (result still a tibble)
gapminder %>% # Ctrl + Shift + m
  select(country, 
         year, 
         pop)

# can also remove:
# install.packages("janitor")
library(janitor)
gapminder %>% 
  select(-pop) %>% 
  clean_names()
```
You can negative select (delete) using a `-` in front of the variable name.
Just because we're havig to type a lot, we do `clean_names()` in order to standardize column names

```{r}
gapminder %>% 
  clean_names() %>% 
  select(-gdp_percap) # need to spell using result
                      # of clean names, which is 
                      # evaluated first
```

### mutate()

First we clean up the names, then we send that to `mutate()`, which we use to create new columns in the data, using a variety of neat tricks. First we define some new nonsensical columns using basic arithemtic, then in the same function call, we use those results to calcualte gdp, again, to verify that we are thinking clearly, then we use another funciton (`mean()`). Since we're working with the whole dataset at once, the result of `mean()` will be assigned to each row in the newly created column.
```{r}
gapminder %>% 
  clean_names() %>% 
  mutate(gdp = gdp_percap * pop,
         stationary_births = pop / life_exp,
         stationary_lifetime_gdp_percap = gdp_percap * life_exp,
         
         # recyle things created, immediately if you want:
         gdp_again = stationary_lifetime_gdp_percap * stationary_births,
         
         # you can use functions here
         avg_life_exp = mean(life_exp),
         
         # simple difference
         life_exp_gap = life_exp - avg_life_exp)
```

### operating on groups 

Note, that when we declare groups, these are independent, meaning that what you do in one group doesn't affect the others, so no worries. Groups remain in effect until explicitly removed using `ungroup()`. We are free to declare groups whenever and however we please, as long as there are potential grouping variables in the data.

```{r}
gapminder %>% 
  clean_names() %>% 
  group_by(country) %>% 
  mutate(life_exp_change = life_exp - life_exp[year == min(year)]) %>% 
  ungroup() %>% 
  group_by(year) %>% 
  mutate(life_exp_gap = max(life_exp) - life_exp) %>% 
  ungroup()
```

#### note on selection in vectors

Use square brackets to select from vectors. This works just the same inside `mutate()`, which is what we're doing with `life_exp[year == min(year)]`. In this case `life_exp` and `year` are the same length, and the logical expression produces a `TRUE` or `FALSE` for each value. In this case, there is only one value that satisfies the condition (one max).
```{r}
a <- rnorm(10)
a[a > 0]
a[a == max(a)]
max(a)

b <- runif(10)
a[b > .5]
```

### filter on groups?

The first one picks out the row of data with the highest life expectancy. The second one does the same filter operation but after groups were declared, so we get one value (row) per group. Then we view the line because it's rather famous.
```{r}
gapminder %>% 
  clean_names() %>% 
  filter(life_exp == max(life_exp))

gapminder %>% 
  # first clean up the names
  clean_names() %>% 
  
  # the declare independent groups
  group_by(year) %>% 
  
  # filter down to just the highest life expectancy
  # per year
  filter(life_exp == max(life_exp)) %>% 
  
  # remove the groups
  ungroup() %>% 
  
  # plot the result
  ggplot(mapping = aes(x = year, 
                       y = life_exp)) +
  geom_point(mapping = aes(color = country),
             size = 3) 
```

### `summarize()`

`summarize()` usually reduces the number of rows in your data. Usually you would use it to aggregate, or tabulate, or produce summary statistics of some kind. You can use it within groups or not. If there are no groups, you'll end up with just one row.
```{r}
gapminder %>% 
  clean_names() %>% 
  summarize(total_pop = sum(pop))

gapminder %>% 
  clean_names() %>% 
  group_by(year) %>% 
  summarize(
     gdp = sum(pop * gdp_percap),
     pop = sum(pop)) %>% 
  ggplot(mapping = aes(x = year, y = gdp)) +
  geom_line()
```

Exercise: Make a plot of how GDP has changed over time for each continent in the data.

```{r}
gapminder %>% 
  clean_names() %>% 
  # create GDP summary stat per unique combo of year and continent
  # 1) declare groups
  group_by(continent,year) %>% 
  # 2) do the summary stat
  summarize(gdp = sum(pop * gdp_percap),
            .groups = "drop") %>% # same as following with ungroup()
                                  # but no annoying messages to console
  ggplot(mapping = aes(x = year,
                       y = gdp)) +
  geom_line(mapping = aes(color = continent))+
  scale_y_log10()
```

### toggling between wide and long and back again

We could stack all of the numeric columns like so. But then we need to give them rather general column names to store the data, because the units and concepts are just so different. The main arguments are to specify a column range, then destination columns where we collect the names (from the header) and the values.
```{r}
gapminder %>% 
  clean_names() %>% 
  pivot_longer(c(gdp_percap, life_exp, pop),
               names_to = "variable",
               values_to = "value") #%>% 
  ## go back again
  # pivot_wider(names_from = variable,
  #             values_from = value)
```


Here we spread out years in the columns, necessarily concatenated with the variable names, which sort of simulates how statistical agencies often deliver data. Sometimes in highly formatted spreadsheets. We can stack it as needed using `pivot_longer()`, giving two new variables names to store the old column labels. We split them using a separator character (`names_sep`). That was convoluted in the first instance because we used `_` for everything. But using a `:` is works easy peasy. Finally, you need to spread the original variable names back out over the columns.
```{r}
gapminder %>% 
  clean_names() %>% 
  pivot_wider(names_from = year,
              values_from = c(gdp_percap, life_exp, pop),
              names_sep = ":") %>% 
  # 3:ncol(.) specifies a column range based on position
  pivot_longer(3:ncol(.),
               names_to = c("variable", "year"),
               values_to = "value",
               names_sep = ":") %>% 
  # final step to get back to what we started with
  pivot_wider(names_from = variable,
              values_from = value)
```

Note to self: include the convoluted solution after class (i.e. where everything is underscore separated)

## Main data exercise for today

Download the data linked in the Google Doc and save it in a folder in your project workspace called `Data`.

```{r}
library(haven)
tu <- read_sav("Data/caseid_aggr.sav")
dim(tu)
head(tu[, 1:20])
```

Create a potentially instrumental data object to store the activity codes and labels:

```{r}
activities <- 
  tu %>% 
  # pull() extracts a column to a vector
  pull(time_300_max) %>% 
  
  # unique() asks what are the actual values present
  # in the vector
  unique() %>% 
  
  # extract the label attribute. Now we have a vector
  # of codes (numeric) with activity labels, seems like
  # it could be useful
  attr("labels")

activities
```

Down sample for the purpose of designing the pipeline, which is iterative in nature. Meaning that as we try things, we keep re-running it.
```{r}
tu2 <- 
  tu %>% 
  sample_n(1000)
```
`sample_n()` takes a random sample of rows from the data.

Let's stack the different minute observations to make this data more pliable. We collect all columns from the one called `time_1_max` (4:00) until whatever the final column is. Column names go to a new column called `time` and the activity codes go to a column called `activity`
```{r}
# how many minutes are in a day??
60*24

tu3 <-
  tu2 %>% 
  pivot_longer(time_1_max:ncol(.),
               #time_1_max:time_1440_max,
               names_to = "time",
               values_to = "activity") %>% 
  select(WT06, time, activity)

```






